{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1840e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = \"gpt4\"\n",
    "model = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "240274ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "def work_on(input):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=deployment, # 如果直接访问OpenAI GPT服务的同学，这里不要使用engine这个参数，要使用model，如： model=“gpt-4”\n",
    "        model = model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a senior software engineer.\"},   \n",
    "            {\"role\": \"user\", \"content\": input}\n",
    "        ],\n",
    "        temperature = 0.9, \n",
    "        max_tokens = 1000,\n",
    "      )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037eaaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是一个简单的HPA配置样例，你可以根据你的需求进行修改：\n",
      "\n",
      "```yaml\n",
      "apiVersion: autoscaling/v2beta2\n",
      "kind: HorizontalPodAutoscaler\n",
      "metadata:\n",
      "  name: nginx-deployment-hpa\n",
      "  namespace: default\n",
      "spec:\n",
      "  scaleTargetRef:\n",
      "    apiVersion: apps/v1\n",
      "    kind: Deployment\n",
      "    name: nginx-deployment\n",
      "  minReplicas: 2\n",
      "  maxReplicas: 10\n",
      "  metrics:\n",
      "  - type: Resource\n",
      "    resource:\n",
      "      name: cpu\n",
      "      target:\n",
      "        type: Utilization\n",
      "        averageUtilization: 60\n",
      "```\n",
      "这个配置会根据CPU利用率来自动调节nginx-deployment的Pod数量，当CPU利用率超过60%时，会自动增加Pod的数量（最多不超过10个）；当CPU利用率低于60%时，会自动减少Pod的数量（最少保留2个）。\n",
      "\n",
      "这个HPA配置使用的是autoscaling/v2beta2版本的API，这个版本的API支持更多的度量标准类型和更灵活的目标指定，同时也更符合Kubernetes约定的API风格。\n"
     ]
    }
   ],
   "source": [
    "print(work_on(\n",
    "\"\"\"\n",
    "为部署kubernetes nginx-deployment写一个HPA配置\n",
    "集群的pod数在2到10之间，目标CPU 利用率60%\n",
    "\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2363437a",
   "metadata": {},
   "source": [
    "# Transformer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ba8ecdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (4.29.2)\n",
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/13/30/54b59e73400df3de506ad8630284e9fd63f4b94f735423d55fc342181037/transformers-4.33.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.33.1-py3-none-any.whl.metadata (119 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m728.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/34/0e/12d55d5dd648b8f7ea7216c5b7cef9703b4dbd3b2a042872c711d5e98551/safetensors-0.3.3-cp311-cp311-macosx_13_0_arm64.whl.metadata\n",
      "  Downloading safetensors-0.3.3-cp311-cp311-macosx_13_0_arm64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.3.3-cp311-cp311-macosx_13_0_arm64.whl (406 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m406.9/406.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.29.2\n",
      "    Uninstalling transformers-4.29.2:\n",
      "      Successfully uninstalled transformers-4.29.2\n",
      "Successfully installed safetensors-0.3.3 transformers-4.33.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d44765ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption(input):\n",
    "    output = pipe(input)\n",
    "    return output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04ddde24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://free-images.com/md/7687/blue_jay_bird_nature.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "araffy blue jay sitting on a tree stump in the winter\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "image_url = \"https://free-images.com/md/7687/blue_jay_bird_nature.jpg\"\n",
    "#image_url = \"/Users/mbj0593/Downloads/blue_jay_bird_nature.jpg\"\n",
    "display(Image(url=image_url)) \n",
    "print(caption(image_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f95fbe5",
   "metadata": {},
   "source": [
    "# 看图说话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "394f2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "def write_a_story(request):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=deployment, # 如果直接访问OpenAI GPT服务的同学，这里不要使用engine这个参数，要使用model，如： model=“gpt-4”\n",
    "        temperature = 0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"\"\n",
    "              You are a novel writer, please, write a small story (about 200 words) in Chinese according to user input,\n",
    "              \"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": request}\n",
    "        ]\n",
    "      )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9679742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://free-images.com/sm/9e46/white_bengal_tiger_tiger_0.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在动物园的一片绿色草坪上，躺着一只白虎。它的皮毛洁白如雪，眼睛闪烁着神秘的光芒。白虎慵懒地躺在草坪上，享受着阳光的沐浴，仿佛是一位高贵的君王。\n",
      "\n",
      "白虎的身边，小朋友们兴奋地围观，他们的眼睛都被这只罕见的白虎吸引住了。他们纷纷拿出手机，拍下这一难得的景象。白虎似乎并不介意这些小朋友的围观，它依然悠然自得地躺在草坪上。\n",
      "\n",
      "突然，白虎慢慢地抬起头，它的眼睛直视着远方。所有的小朋友都屏住了呼吸，他们惊奇地看着白虎。白虎似乎看到了什么，它突然从草坪上跃起，向远方奔去。\n",
      "\n",
      "小朋友们惊讶地看着白虎的背影，他们都想知道白虎看到了什么。但是，他们只能看着白虎消失在远方，留下一片空荡荡的草坪和他们的惊奇。\n"
     ]
    }
   ],
   "source": [
    "image_url = \"https://free-images.com/sm/9e46/white_bengal_tiger_tiger_0.jpg\"\n",
    "display(Image(url=image_url)) \n",
    "print(write_a_story(caption(image_url)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc9a24",
   "metadata": {},
   "source": [
    "# LangChain + HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bf29ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['HUGGINGFACEHUB_API_TOKEN']='your key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed651c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = HuggingFaceHub(repo_id=\"bigscience/bloom\", model_kwargs={\"temperature\": 0.5, \"max_length\": 64})\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"hints\"],\n",
    "    template = \"A story about the bird \\n{hints}. \"\n",
    ")\n",
    "chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "print(chain.run(\"araffy blue jay sitting on a tree stump in the winter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83d42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
