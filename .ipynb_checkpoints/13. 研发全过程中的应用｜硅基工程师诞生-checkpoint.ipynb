{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2498ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = \"gpt4\"\n",
    "model = \"gpt-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77bb728",
   "metadata": {},
   "source": [
    "# LLM辅助设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a010569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a simplified version of a Twitter-like system represented as a PlantUML class diagram:\n",
      "\n",
      "```plantuml\n",
      "@startuml\n",
      "class User {\n",
      "  +username: String\n",
      "  +password: String\n",
      "  +email: String\n",
      "  +createPost(content: String): Post\n",
      "  +follow(user: User): void\n",
      "  +unfollow(user: User): void\n",
      "}\n",
      "\n",
      "class Post {\n",
      "  +content: String\n",
      "  +timestamp: Date\n",
      "  +user: User\n",
      "  +like(user: User): void\n",
      "  +unlike(user: User): void\n",
      "  +addComment(user: User, content: String): Comment\n",
      "}\n",
      "\n",
      "class Comment {\n",
      "  +content: String\n",
      "  +timestamp: Date\n",
      "  +user: User\n",
      "  +post: Post\n",
      "  +like(user: User): void\n",
      "  +unlike(user: User): void\n",
      "}\n",
      "\n",
      "class Notification {\n",
      "  +content: String\n",
      "  +timestamp: Date\n",
      "  +user: User\n",
      "}\n",
      "\n",
      "User \"1\" -- \"0..*\" User: follows\n",
      "User \"1\" -- \"0..*\" Post: posts\n",
      "Post \"1\" -- \"0..*\" Comment: comments\n",
      "User \"1\" -- \"0..*\" Comment: comments\n",
      "User \"1\" -- \"0..*\" Notification: notifications\n",
      "@enduml\n",
      "```\n",
      "\n",
      "In this model:\n",
      "\n",
      "- A `User` can create `Post`s, follow and unfollow other `User`s, and receive `Notification`s.\n",
      "- A `Post` can be liked and unliked by `User`s, and `User`s can add `Comment`s to it.\n",
      "- A `Comment` can also be liked and unliked by `User`s.\n",
      "- A `User` can have many `Post`s, follow many other `User`s, and have many `Notification`s.\n",
      "- A `Post` can have many `Comment`s, and a `Comment` is associated with one `User` and one `Post`.\n",
      "\n",
      "This is a very simplified model and doesn't include many features of a real Twitter-like system, such as retweets, direct messages, hashtags, etc. But it should give you a good starting point.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=deployment, # 如果直接访问OpenAI GPT服务的同学，这里不要使用engine这个参数，要使用model，如： model=“gpt-4”\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a senior software engineer.\"},   \n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "          Design a twitter like system, represent the business domain model with PlantUML script\n",
    "          \"\"\"}\n",
    "    ],\n",
    "    temperature = 0.2, \n",
    "    max_tokens = 500\n",
    "  )\n",
    "print(response.choices[0].message.content)\n",
    "# http://www.plantuml.com/plantuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8c121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is a simplified example of a Facebook-like system represented by a UML sequence diagram using PlantUML script. This example includes a User, a Post, a Comment, and a Like system.\n",
      "\n",
      "```plantuml\n",
      "@startuml\n",
      "participant User\n",
      "participant Post\n",
      "participant Comment\n",
      "participant Like\n",
      "\n",
      "User -> Post: CreatePost(content)\n",
      "activate Post\n",
      "Post --> User: PostID\n",
      "deactivate Post\n",
      "\n",
      "User -> Comment: CreateComment(PostID, content)\n",
      "activate Comment\n",
      "Comment --> User: CommentID\n",
      "deactivate Comment\n",
      "\n",
      "User -> Like: LikePost(PostID)\n",
      "activate Like\n",
      "Like --> User: Acknowledge\n",
      "deactivate Like\n",
      "\n",
      "User -> Like: LikeComment(CommentID)\n",
      "activate Like\n",
      "Like --> User: Acknowledge\n",
      "deactivate Like\n",
      "@enduml\n",
      "```\n",
      "\n",
      "In this sequence diagram:\n",
      "\n",
      "1. A User creates a Post, which returns a PostID.\n",
      "2. The User then creates a Comment on that Post, which returns a CommentID.\n",
      "3. The User likes the Post, and the Like system acknowledges the action.\n",
      "4. Finally, the User likes the Comment, and the Like system acknowledges the action.\n",
      "\n",
      "Please note that this is a simplified version of a Facebook-like system. A real-world system would be much more complex and would involve many more components and interactions.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=deployment, # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a senior software engineer.\"},   \n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "          Design a facebook like system, represent the interactions by UML sequence diagram with PlantUML script\n",
    "          \"\"\"}\n",
    "    ],\n",
    "    temperature = 0.2, \n",
    "    max_tokens = 500\n",
    "  )\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6bc8355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# from langchain.chat_models import ChatOpenAI #直接访问OpenAI的GPT服务\n",
    "\n",
    "#llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0) #直接访问OpenAI的GPT服务\n",
    "llm = AzureChatOpenAI(deployment_name = deployment, model_name=model, temperature=0, max_tokens=1000) #通过Azure的OpenAI服务\n",
    "\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=10) \n",
    "\n",
    "\n",
    "def get_response(input):\n",
    "    conversation_with_memory = ConversationChain(\n",
    "        llm=llm, \n",
    "        memory=memory,\n",
    "        verbose=False\n",
    "    )\n",
    "    return conversation_with_memory.predict(input=input)\n",
    "\n",
    "import gradio as gr\n",
    "def respond(message, chat_history):\n",
    "    bot_message = get_response(message)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=300) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "demo.launch()\n",
    "\n",
    "#生成一个观察者模式类图，用plantUML script表示\n",
    "#根据上面的UML生成Java代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d969ddb",
   "metadata": {},
   "source": [
    "# LLM生成代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0199eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class TokenCreator(ABC):\n",
    "    @abstractmethod\n",
    "    # create the token with uuid\n",
    "    def create_token(self, input)->str:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07df4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "def work_on(input):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=deployment, # 如果直接访问OpenAI GPT服务的同学，这里不要使用engine这个参数，要使用model，如： model=“gpt-4”\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a senior software engineer.\"},   \n",
    "            {\"role\": \"user\", \"content\": input}\n",
    "        ],\n",
    "        temperature = 0, \n",
    "        max_tokens = 500\n",
    "      )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49cbb14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface_def = \"\"\"\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class TokenCreator(ABC):\n",
    "    @abstractmethod\n",
    "    # create the token with uuid + input\n",
    "    def create_token(self, input)->str:\n",
    "        pass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d52a5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is a concrete implementation of the abstract class `TokenCreator` using Python's built-in `uuid` module to generate a unique identifier:\n",
      "\n",
      "```python\n",
      "import uuid\n",
      "from abc import ABC, abstractmethod\n",
      "\n",
      "class TokenCreator(ABC):\n",
      "    @abstractmethod\n",
      "    def create_token(self, input)->str:\n",
      "        pass\n",
      "\n",
      "class MyTokenCreator(TokenCreator):\n",
      "    def create_token(self, input)->str:\n",
      "        return str(uuid.uuid4()) + input\n",
      "```\n",
      "\n",
      "In this implementation, `MyTokenCreator` is a concrete class that inherits from the abstract base class `TokenCreator`. It provides an implementation for the `create_token` method, which generates a new UUID and concatenates it with the input string.\n"
     ]
    }
   ],
   "source": [
    "print(work_on(\"Implement the following abstract class. \\n --- \\n\"+ interface_def))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "585c167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d0f71684-01a6-45b2-a26a-1d023b960120Hello\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class TokenCreator(ABC):\n",
    "    @abstractmethod\n",
    "    def create_token(self, input)->str:\n",
    "        pass\n",
    "\n",
    "class UUIDTokenCreator(TokenCreator):\n",
    "    def create_token(self, input)->str:\n",
    "        return str(uuid.uuid4()) + str(input)\n",
    "    \n",
    "mtc = UUIDTokenCreator()\n",
    "print(mtc.create_token(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782ca7af",
   "metadata": {},
   "source": [
    "# 生成单元测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e91dbbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is a simple unit test for the UUIDTokenCreator class using Python's built-in unittest module:\n",
      "\n",
      "```python\n",
      "import unittest\n",
      "import uuid\n",
      "from abc import ABC, abstractmethod\n",
      "\n",
      "class TokenCreator(ABC):\n",
      "    @abstractmethod\n",
      "    def create_token(self, input)->str:\n",
      "        pass\n",
      "\n",
      "class UUIDTokenCreator(TokenCreator):\n",
      "    def create_token(self, input)->str:\n",
      "        return str(uuid.uuid4()) + str(input)\n",
      "\n",
      "class TestUUIDTokenCreator(unittest.TestCase):\n",
      "    def setUp(self):\n",
      "        self.token_creator = UUIDTokenCreator()\n",
      "\n",
      "    def test_create_token(self):\n",
      "        input = \"test\"\n",
      "        token = self.token_creator.create_token(input)\n",
      "        self.assertTrue(isinstance(token, str))\n",
      "        self.assertTrue(token.endswith(input))\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "```\n",
      "\n",
      "This test case checks if the `create_token` method of the `UUIDTokenCreator` class returns a string and if the returned string ends with the input string. The `setUp` method is used to initialize the `UUIDTokenCreator` object before each test.\n"
     ]
    }
   ],
   "source": [
    "prog = \"\"\"\n",
    "import uuid\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class TokenCreator(ABC):\n",
    "    @abstractmethod\n",
    "    def create_token(self, input)->str:\n",
    "        pass\n",
    "\n",
    "class UUIDTokenCreator(TokenCreator):\n",
    "    def create_token(self, input)->str:\n",
    "        return str(uuid.uuid4()) + str(input)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(work_on(\"Write the unit test (the unit test in the same module) for the class UUIDTokenCreator in the following code: \\n --- \\n\"+ prog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358df5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x10623ded0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import uuid\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class TokenCreator(ABC):\n",
    "    @abstractmethod\n",
    "    def create_token(self, input)->str:\n",
    "        pass\n",
    "\n",
    "class UUIDTokenCreator(TokenCreator):\n",
    "    def create_token(self, input)->str:\n",
    "        return str(uuid.uuid4()) + str(input)\n",
    "\n",
    "class TestUUIDTokenCreator(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.token_creator = UUIDTokenCreator()\n",
    "\n",
    "    def test_create_token(self):\n",
    "        input = \"test\"\n",
    "        token = self.token_creator.create_token(input)\n",
    "        self.assertTrue(isinstance(token, str))\n",
    "        self.assertTrue(token.endswith(input))\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    unittest.main()\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647f4d7",
   "metadata": {},
   "source": [
    "# 代码理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a25caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是一个基本的Python函数，使用了requests和BeautifulSoup库来获取和解析网页内容。\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def get_webpage_text(url):\n",
      "    try:\n",
      "        # 发送HTTP请求\n",
      "        response = requests.get(url)\n",
      "        # 检查请求是否成功\n",
      "        response.raise_for_status()\n",
      "    except requests.RequestException as e:\n",
      "        print(f\"请求失败: {e}\")\n",
      "        return None\n",
      "\n",
      "    # 使用BeautifulSoup解析HTML内容\n",
      "    soup = BeautifulSoup(response.content, 'html.parser')\n",
      "\n",
      "    # 获取所有的段落标签\n",
      "    paragraphs = soup.find_all('p')\n",
      "\n",
      "    # 提取并返回所有段落的文本\n",
      "    return '\\n'.join([p.get_text() for p in paragraphs])\n",
      "\n",
      "# 测试函数\n",
      "print(get_webpage_text('https://www.example.com'))\n",
      "```\n",
      "\n",
      "这个函数只会返回`<p>`标签中的文本，如果你想获取其他标签的文本，你可以修改`find_all('p')`中的`'p'`为你想要的标签。\n",
      "\n",
      "注意：这个函数可能无法获取到一些由JavaScript动态生成的内容，因为requests库不会执行JavaScript代码。如果你需要获取这些内容，你可能需要使用一些更复杂的工具，如Selenium。\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "编写一个Python函数，输入为一个网页地址，输出该页面上的文字内容。\n",
    "\"\"\"\n",
    "\n",
    "print(work_on(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "316109f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_text_from_url(url):\n",
    "    try:\n",
    "        # 发送GET请求获取网页内容\n",
    "        response = requests.get(url)\n",
    "        # 使用BeautifulSoup解析网页内容\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # 获取网页中的所有文本内容\n",
    "        text = soup.get_text()\n",
    "        \n",
    "        # 返回文本内容\n",
    "        return text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # 打印错误信息并返回None\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b61a480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"An agent designed to hold a conversation in addition to using tools.\"\"\"\n",
      "from __future__ import annotations\n",
      "\n",
      "from typing import Any, List, Optional, Sequence\n",
      "\n",
      "from langchain.agents.agent import Agent, AgentOutputParser\n",
      "from langchain.agents.agent_types import AgentType\n",
      "from langchain.agents.conversational.output_parser import ConvoOutputParser\n",
      "from langchain.agents.conversational.prompt import FORMAT_INSTRUCTIONS, PREFIX, SUFFIX\n",
      "from langchain.agents.utils import validate_tools_single_input\n",
      "from langchain.callbacks.base import BaseCallbackManager\n",
      "from langchain.chains import LLMChain\n",
      "from langchain.prompts import PromptTemplate\n",
      "from langchain.pydantic_v1 import Field\n",
      "from langchain.schema.language_model import BaseLanguageModel\n",
      "from langchain.tools.base import BaseTool\n",
      "\n",
      "\n",
      "class ConversationalAgent(Agent):\n",
      "    \"\"\"An agent that holds a conversation in addition to using tools.\"\"\"\n",
      "\n",
      "    ai_prefix: str = \"AI\"\n",
      "    \"\"\"Prefix to use before AI output.\"\"\"\n",
      "    output_parser: AgentOutputParser = Field(default_factory=ConvoOutputParser)\n",
      "    \"\"\"Output parser for the agent.\"\"\"\n",
      "\n",
      "    @classmethod\n",
      "    def _get_default_output_parser(\n",
      "        cls, ai_prefix: str = \"AI\", **kwargs: Any\n",
      "    ) -> AgentOutputParser:\n",
      "        return ConvoOutputParser(ai_prefix=ai_prefix)\n",
      "\n",
      "    @property\n",
      "    def _agent_type(self) -> str:\n",
      "        \"\"\"Return Identifier of agent type.\"\"\"\n",
      "        return AgentType.CONVERSATIONAL_REACT_DESCRIPTION\n",
      "\n",
      "    @property\n",
      "    def observation_prefix(self) -> str:\n",
      "        \"\"\"Prefix to append the observation with.\"\"\"\n",
      "        return \"Observation: \"\n",
      "\n",
      "    @property\n",
      "    def llm_prefix(self) -> str:\n",
      "        \"\"\"Prefix to append the llm call with.\"\"\"\n",
      "        return \"Thought:\"\n",
      "\n",
      "    @classmethod\n",
      "    def create_prompt(\n",
      "        cls,\n",
      "        tools: Sequence[BaseTool],\n",
      "        prefix: str = PREFIX,\n",
      "        suffix: str = SUFFIX,\n",
      "        format_instructions: str = FORMAT_INSTRUCTIONS,\n",
      "        ai_prefix: str = \"AI\",\n",
      "        human_prefix: str = \"Human\",\n",
      "        input_variables: Optional[List[str]] = None,\n",
      "    ) -> PromptTemplate:\n",
      "        \"\"\"Create prompt in the style of the zero-shot agent.\n",
      "\n",
      "        Args:\n",
      "            tools: List of tools the agent will have access to, used to format the\n",
      "                prompt.\n",
      "            prefix: String to put before the list of tools.\n",
      "            suffix: String to put after the list of tools.\n",
      "            ai_prefix: String to use before AI output.\n",
      "            human_prefix: String to use before human output.\n",
      "            input_variables: List of input variables the final prompt will expect.\n",
      "\n",
      "        Returns:\n",
      "            A PromptTemplate with the template assembled from the pieces here.\n",
      "        \"\"\"\n",
      "        tool_strings = \"\\n\".join(\n",
      "            [f\"> {tool.name}: {tool.description}\" for tool in tools]\n",
      "        )\n",
      "        tool_names = \", \".join([tool.name for tool in tools])\n",
      "        format_instructions = format_instructions.format(\n",
      "            tool_names=tool_names, ai_prefix=ai_prefix, human_prefix=human_prefix\n",
      "        )\n",
      "        template = \"\\n\\n\".join([prefix, tool_strings, format_instructions, suffix])\n",
      "        if input_variables is None:\n",
      "            input_variables = [\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
      "        return PromptTemplate(template=template, input_variables=input_variables)\n",
      "\n",
      "    @classmethod\n",
      "    def _validate_tools(cls, tools: Sequence[BaseTool]) -> None:\n",
      "        super()._validate_tools(tools)\n",
      "        validate_tools_single_input(cls.__name__, tools)\n",
      "\n",
      "    @classmethod\n",
      "    def from_llm_and_tools(\n",
      "        cls,\n",
      "        llm: BaseLanguageModel,\n",
      "        tools: Sequence[BaseTool],\n",
      "        callback_manager: Optional[BaseCallbackManager] = None,\n",
      "        output_parser: Optional[AgentOutputParser] = None,\n",
      "        prefix: str = PREFIX,\n",
      "        suffix: str = SUFFIX,\n",
      "        format_instructions: str = FORMAT_INSTRUCTIONS,\n",
      "        ai_prefix: str = \"AI\",\n",
      "        human_prefix: str = \"Human\",\n",
      "        input_variables: Optional[List[str]] = None,\n",
      "        **kwargs: Any,\n",
      "    ) -> Agent:\n",
      "        \"\"\"Construct an agent from an LLM and tools.\"\"\"\n",
      "        cls._validate_tools(tools)\n",
      "        prompt = cls.create_prompt(\n",
      "            tools,\n",
      "            ai_prefix=ai_prefix,\n",
      "            human_prefix=human_prefix,\n",
      "            prefix=prefix,\n",
      "            suffix=suffix,\n",
      "            format_instructions=format_instructions,\n",
      "            input_variables=input_variables,\n",
      "        )\n",
      "        llm_chain = LLMChain(\n",
      "            llm=llm,\n",
      "            prompt=prompt,\n",
      "            callback_manager=callback_manager,\n",
      "        )\n",
      "        tool_names = [tool.name for tool in tools]\n",
      "        _output_parser = output_parser or cls._get_default_output_parser(\n",
      "            ai_prefix=ai_prefix\n",
      "        )\n",
      "        return cls(\n",
      "            llm_chain=llm_chain,\n",
      "            allowed_tools=tool_names,\n",
      "            ai_prefix=ai_prefix,\n",
      "            output_parser=_output_parser,\n",
      "            **kwargs,\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_text_from_url(\"https://raw.githubusercontent.com/langchain-ai/langchain/master/libs/langchain/langchain/agents/conversational/base.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afd0c2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个程序定义了一个名为`ConversationalAgent`的类，它是`Agent`类的子类。`ConversationalAgent`是一个可以进行对话并使用工具的代理。\n",
      "\n",
      "以下是类的主要属性和方法：\n",
      "\n",
      "- `ai_prefix`: AI输出前的前缀，默认为\"AI\"。\n",
      "- `output_parser`: 代理的输出解析器，默认为`ConvoOutputParser`。\n",
      "- `_get_default_output_parser`: 返回默认的输出解析器，可以通过参数`ai_prefix`自定义AI输出前的前缀。\n",
      "- `_agent_type`: 返回代理类型的标识符，这里是`AgentType.CONVERSATIONAL_REACT_DESCRIPTION`。\n",
      "- `observation_prefix`和`llm_prefix`: 分别返回观察和llm调用的前缀。\n",
      "- `create_prompt`: 创建零射击代理的提示。这个方法需要一系列的参数，包括代理将访问的工具列表、前缀、后缀、格式指令、AI前缀、人类前缀和输入变量列表。返回一个由这些部分组成的`PromptTemplate`。\n",
      "- `_validate_tools`: 验证工具，确保它们是有效的。\n",
      "- `from_llm_and_tools`: 从LLM和工具构造一个代理。这个方法需要一系列的参数，包括LLM、工具、回调管理器、输出解析器、前缀、后缀、格式指令、AI前缀、人类前缀和输入变量列表。返回一个新的`ConversationalAgent`实例。\n",
      "\n",
      "这个类的主要功能是创建和管理一个可以进行对话并使用工具的代理。\n"
     ]
    }
   ],
   "source": [
    "code = get_text_from_url(\"https://raw.githubusercontent.com/langchain-ai/langchain/master/libs/langchain/langchain/agents/conversational/base.py\")\n",
    "print(work_on(\"分析下面的程序：\\n ---- \\n\"+ code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de5b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
